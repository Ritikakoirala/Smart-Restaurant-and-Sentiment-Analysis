{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8000 records from swiggy.csv\n",
      "Columns: ['ID', 'Area', 'City', 'Restaurant Price', 'Avg Rating', 'Total Rating', 'Food Item', 'Food Type', 'Delivery Time', 'Review']\n"
     ]
    }
   ],
   "source": [
    "# Load the Swiggy dataset\n",
    "data = pd.read_csv('swiggy.csv')\n",
    "print(f\"Loaded {len(data)} records from swiggy.csv\")\n",
    "print(f\"Columns: {data.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentiment distribution:\n",
      "sentiment\n",
      "positive    5727\n",
      "neutral     2273\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "data[\"Review\"] = data[\"Review\"].str.lower()\n",
    "data[\"Review\"] = data[\"Review\"].replace(r'[^a-z0-9\\s]', '', regex=True)\n",
    "data = data.dropna(subset=['Review', 'Avg Rating'])\n",
    "\n",
    "def label_sentiment_num(rating):\n",
    "    if rating <= 2.5:\n",
    "        return \"negative\"\n",
    "    elif rating <= 3.5:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "\n",
    "data['sentiment'] = data['Avg Rating'].apply(label_sentiment_num)\n",
    "print(f\"Original sentiment distribution:\")\n",
    "print(data['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No negative examples found! Adding synthetic negative examples...\n",
      "After adding synthetic negatives:\n",
      "sentiment\n",
      "positive    5727\n",
      "neutral     2273\n",
      "negative    2000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if we have negative examples\n",
    "negative_count = len(data[data['sentiment'] == 'negative'])\n",
    "\n",
    "if negative_count == 0:\n",
    "    print(\"No negative examples found! Adding synthetic negative examples...\")\n",
    "    \n",
    "    # Common negative phrases for restaurant reviews\n",
    "    negative_phrases = [\n",
    "        \"terrible food and bad service\",\n",
    "        \"worst experience ever\",\n",
    "        \"cold and tasteless food\",\n",
    "        \"disgusting and overpriced\",\n",
    "        \"horrible delivery and rude staff\",\n",
    "        \"never order from here again\",\n",
    "        \"waste of money and time\",\n",
    "        \"food was terrible and cold\",\n",
    "        \"very bad service and slow\",\n",
    "        \"disappointed with the quality\",\n",
    "        \"tasteless and bland food\",\n",
    "        \"late delivery and wrong order\",\n",
    "        \"poor quality and expensive\",\n",
    "        \"awful experience and rude\",\n",
    "        \"bad taste and dirty place\",\n",
    "        \"not fresh and overcooked\",\n",
    "        \"unhygienic and unhealthy\",\n",
    "        \"worse than expected and cold\",\n",
    "        \"cheap quality and small portions\",\n",
    "        \"unpleasant and frustrating service\"\n",
    "    ]\n",
    "    \n",
    "    # Create synthetic negative examples\n",
    "    synthetic_negative = pd.DataFrame({\n",
    "        'Review': negative_phrases * 100,\n",
    "        'sentiment': ['negative'] * (len(negative_phrases) * 100),\n",
    "        'Avg Rating': [2.0] * (len(negative_phrases) * 100)\n",
    "    })\n",
    "    \n",
    "    # Add to original data\n",
    "    data = pd.concat([data[['Review', 'sentiment', 'Avg Rating']], synthetic_negative], ignore_index=True)\n",
    "    print(\"After adding synthetic negatives:\")\n",
    "    print(data['sentiment'].value_counts())\n",
    "else:\n",
    "    print(f\"Found {negative_count} negative examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e35cfcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Area</th>\n",
       "      <th>City</th>\n",
       "      <th>Restaurant Price</th>\n",
       "      <th>Avg Rating</th>\n",
       "      <th>Total Rating</th>\n",
       "      <th>Food Item</th>\n",
       "      <th>Food Type</th>\n",
       "      <th>Delivery Time</th>\n",
       "      <th>Review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Suburb</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>600</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6198</td>\n",
       "      <td>Sushi</td>\n",
       "      <td>Fast Food</td>\n",
       "      <td>30-40 min</td>\n",
       "      <td>good but nothing extraordinary</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Business District</td>\n",
       "      <td>Pune</td>\n",
       "      <td>200</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4865</td>\n",
       "      <td>Pepperoni Pizza</td>\n",
       "      <td>Non-Vegetarian</td>\n",
       "      <td>50-60 min</td>\n",
       "      <td>good but nothing extraordinary</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Suburb</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>600</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2095</td>\n",
       "      <td>Waffles</td>\n",
       "      <td>Fast Food</td>\n",
       "      <td>50-60 min</td>\n",
       "      <td>late delivery ruined it</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Business District</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>900</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6639</td>\n",
       "      <td>Sushi</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>50-60 min</td>\n",
       "      <td>best meal ive had in a while</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tech Park</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>200</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6926</td>\n",
       "      <td>Spring Rolls</td>\n",
       "      <td>Gluten-Free</td>\n",
       "      <td>20-30 min</td>\n",
       "      <td>mediocre experience</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID               Area       City  Restaurant Price  Avg Rating  \\\n",
       "0   1             Suburb  Ahmedabad               600         4.2   \n",
       "1   2  Business District       Pune               200         4.7   \n",
       "2   3             Suburb  Bangalore               600         4.7   \n",
       "3   4  Business District     Mumbai               900         4.0   \n",
       "4   5          Tech Park     Mumbai               200         4.7   \n",
       "\n",
       "   Total Rating        Food Item       Food Type Delivery Time  \\\n",
       "0          6198            Sushi       Fast Food     30-40 min   \n",
       "1          4865  Pepperoni Pizza  Non-Vegetarian     50-60 min   \n",
       "2          2095          Waffles       Fast Food     50-60 min   \n",
       "3          6639            Sushi      Vegetarian     50-60 min   \n",
       "4          6926     Spring Rolls     Gluten-Free     20-30 min   \n",
       "\n",
       "                           Review sentiment  \n",
       "0  good but nothing extraordinary  positive  \n",
       "1  good but nothing extraordinary  positive  \n",
       "2         late delivery ruined it  positive  \n",
       "3    best meal ive had in a while  positive  \n",
       "4             mediocre experience  positive  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b64a4ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04fb9a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   ID                8000 non-null   int64  \n",
      " 1   Area              8000 non-null   object \n",
      " 2   City              8000 non-null   object \n",
      " 3   Restaurant Price  8000 non-null   int64  \n",
      " 4   Avg Rating        8000 non-null   float64\n",
      " 5   Total Rating      8000 non-null   int64  \n",
      " 6   Food Item         8000 non-null   object \n",
      " 7   Food Type         8000 non-null   object \n",
      " 8   Delivery Time     8000 non-null   object \n",
      " 9   Review            8000 non-null   object \n",
      " 10  sentiment         8000 non-null   object \n",
      "dtypes: float64(1), int64(3), object(7)\n",
      "memory usage: 687.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02acbab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Restaurant Price</th>\n",
       "      <th>Avg Rating</th>\n",
       "      <th>Total Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.00000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4000.50000</td>\n",
       "      <td>544.587500</td>\n",
       "      <td>4.129900</td>\n",
       "      <td>4979.977500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2309.54541</td>\n",
       "      <td>287.968871</td>\n",
       "      <td>0.645791</td>\n",
       "      <td>2877.285148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2000.75000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4000.50000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>4989.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6000.25000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>7498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Restaurant Price   Avg Rating  Total Rating\n",
       "count  8000.00000       8000.000000  8000.000000   8000.000000\n",
       "mean   4000.50000        544.587500     4.129900   4979.977500\n",
       "std    2309.54541        287.968871     0.645791   2877.285148\n",
       "min       1.00000        100.000000     3.000000     51.000000\n",
       "25%    2000.75000        300.000000     3.500000   2476.000000\n",
       "50%    4000.50000        500.000000     4.200000   4989.500000\n",
       "75%    6000.25000        800.000000     4.700000   7498.000000\n",
       "max    8000.00000       1000.000000     5.000000  10000.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15b760d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 72\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary\n",
    "max_features = 5000\n",
    "max_length = 200\n",
    "\n",
    "def build_vocab(texts, max_features=None):\n",
    "    word_counts = {}\n",
    "    for text in texts:\n",
    "        for word in str(text).split():\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "    \n",
    "    sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if max_features:\n",
    "        sorted_words = sorted_words[:max_features]\n",
    "    \n",
    "    word_index = {word: idx+1 for idx, (word, _) in enumerate(sorted_words)}\n",
    "    return word_index\n",
    "\n",
    "word_index = build_vocab(data[\"Review\"].tolist(), max_features=max_features)\n",
    "print(f\"Vocabulary size: {len(word_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8000, 200), y shape: (8000,)\n"
     ]
    }
   ],
   "source": [
    "# Convert texts to sequences\n",
    "def texts_to_sequences(texts, word_index):\n",
    "    sequences = []\n",
    "    for text in texts:\n",
    "        seq = [word_index.get(word, 0) for word in str(text).split()]\n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "\n",
    "sequences = texts_to_sequences(data[\"Review\"].tolist(), word_index)\n",
    "\n",
    "# Pad sequences\n",
    "def pad_sequences_custom(sequences, maxlen):\n",
    "    padded = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) < maxlen:\n",
    "            seq = [0]*(maxlen - len(seq)) + seq\n",
    "        else:\n",
    "            seq = seq[:maxlen]\n",
    "        padded.append(seq)\n",
    "    return np.array(padded)\n",
    "\n",
    "X = pad_sequences_custom(sequences, max_length)\n",
    "y = data['sentiment'].values\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label classes: ['neutral' 'positive']\n",
      "Train distribution: [1636 4124]\n",
      "Test distribution: [ 455 1145]\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "# Encode labels\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_val_encoded = encoder.transform(y_val)\n",
    "y_test_encoded = encoder.transform(y_test)\n",
    "\n",
    "print(f\"Label classes: {encoder.classes_}\")\n",
    "print(f\"Train distribution: {np.bincount(y_train_encoded)}\")\n",
    "print(f\"Test distribution: {np.bincount(y_test_encoded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 233ms/step - accuracy: 0.7160 - loss: 0.5969 - val_accuracy: 0.7156 - val_loss: 0.5999\n",
      "Epoch 2/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 232ms/step - accuracy: 0.7160 - loss: 0.5968 - val_accuracy: 0.7156 - val_loss: 0.5963\n",
      "Epoch 3/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 287ms/step - accuracy: 0.7160 - loss: 0.5981 - val_accuracy: 0.7156 - val_loss: 0.6003\n",
      "Epoch 4/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 390ms/step - accuracy: 0.7160 - loss: 0.5977 - val_accuracy: 0.7156 - val_loss: 0.5991\n",
      "Epoch 5/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 371ms/step - accuracy: 0.7160 - loss: 0.5969 - val_accuracy: 0.7156 - val_loss: 0.5970\n",
      "Epoch 6/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 311ms/step - accuracy: 0.7160 - loss: 0.5963 - val_accuracy: 0.7156 - val_loss: 0.5961\n",
      "Epoch 7/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 229ms/step - accuracy: 0.7160 - loss: 0.5976 - val_accuracy: 0.7156 - val_loss: 0.6055\n",
      "Epoch 8/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 220ms/step - accuracy: 0.7160 - loss: 0.5969 - val_accuracy: 0.7156 - val_loss: 0.5975\n",
      "Epoch 9/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 232ms/step - accuracy: 0.7160 - loss: 0.5967 - val_accuracy: 0.7156 - val_loss: 0.5964\n",
      "Epoch 10/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 220ms/step - accuracy: 0.7160 - loss: 0.5966 - val_accuracy: 0.7156 - val_loss: 0.5960\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.7156 - loss: 0.5974\n",
      "Test Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Training model...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train_encoded,\n",
    "    validation_data=(X_val, y_val_encoded),\n",
    "    epochs=10,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, acc = model.evaluate(X_test, y_test_encoded)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model and artifacts...\n",
      "Saved: smartapp/sentiment_model.h5\n",
      "Saved: smartapp/word_index.pkl\n",
      "Saved: smartapp/label_encoder.pkl\n",
      "Saved: smartapp/model_config.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the model and artifacts\n",
    "print(\"Saving model and artifacts...\")\n",
    "\n",
    "# Save Keras model\n",
    "model.save('smartapp/sentiment_model.h5')\n",
    "print(\"Saved: smartapp/sentiment_model.h5\")\n",
    "\n",
    "# Save word_index\n",
    "with open('smartapp/word_index.pkl', 'wb') as f:\n",
    "    pickle.dump(word_index, f)\n",
    "print(\"Saved: smartapp/word_index.pkl\")\n",
    "\n",
    "# Save label encoder\n",
    "with open('smartapp/label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder, f)\n",
    "print(\"Saved: smartapp/label_encoder.pkl\")\n",
    "\n",
    "# Save max_length for later use\n",
    "with open('smartapp/model_config.pkl', 'wb') as f:\n",
    "    pickle.dump({'max_length': max_length, 'max_features': max_features}, f)\n",
    "print(\"Saved: smartapp/model_config.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing saved model...\n",
      "Test Results:\n",
      "Review: 'The food was amazing and delicious!'\n",
      "  Sentiment: positive (67.5%)\n",
      "Review: 'Terrible service and cold food'\n",
      "  Sentiment: positive (69.8%)\n",
      "Review: 'It was okay, nothing special'\n",
      "  Sentiment: positive (67.1%)\n",
      "Review: 'Best restaurant ever, highly recommend!'\n",
      "  Sentiment: positive (67.8%)\n",
      "Review: 'Worst experience ever, never coming back'\n",
      "  Sentiment: positive (68.0%)\n",
      "Review: 'Fresh and tasty, will order again'\n",
      "  Sentiment: positive (68.3%)\n",
      "Review: 'Hate the long wait and rude staff'\n",
      "  Sentiment: positive (68.1%)\n",
      "Review: 'Average quality but decent'\n",
      "  Sentiment: positive (66.3%)\n",
      "Model training and export complete!\n"
     ]
    }
   ],
   "source": [
    "# Test the saved model\n",
    "print(\"Testing saved model...\")\n",
    "\n",
    "# Load saved artifacts\n",
    "loaded_model = load_model('smartapp/sentiment_model.h5')\n",
    "with open('smartapp/word_index.pkl', 'rb') as f:\n",
    "    loaded_word_index = pickle.load(f)\n",
    "with open('smartapp/label_encoder.pkl', 'rb') as f:\n",
    "    loaded_encoder = pickle.load(f)\n",
    "\n",
    "# Test reviews\n",
    "test_reviews = [\n",
    "    \"The food was amazing and delicious!\",\n",
    "    \"Terrible service and cold food\",\n",
    "    \"It was okay, nothing special\",\n",
    "    \"Best restaurant ever, highly recommend!\",\n",
    "    \"Worst experience ever, never coming back\",\n",
    "    \"Fresh and tasty, will order again\",\n",
    "    \"Hate the long wait and rude staff\",\n",
    "    \"Average quality but decent\"\n",
    "]\n",
    "\n",
    "print(\"Test Results:\")\n",
    "for review in test_reviews:\n",
    "    # Preprocess\n",
    "    text = review.lower().strip()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = text.split()\n",
    "    sequence = [loaded_word_index.get(word, 0) for word in words]\n",
    "    if len(sequence) < max_length:\n",
    "        sequence = [0] * (max_length - len(sequence)) + sequence\n",
    "    else:\n",
    "        sequence = sequence[:max_length]\n",
    "    sequence = np.array([sequence])\n",
    "    \n",
    "    # Predict\n",
    "    pred = loaded_model.predict(sequence, verbose=0)[0]\n",
    "    pred_class = np.argmax(pred)\n",
    "    sentiment = loaded_encoder.inverse_transform([pred_class])[0]\n",
    "    confidence = float(pred[pred_class] * 100)\n",
    "    \n",
    "    print(f\"Review: '{review}'\")\n",
    "    print(f\"  Sentiment: {sentiment} ({confidence:.1f}%)\")\n",
    "\n",
    "print(\"Model training and export complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
