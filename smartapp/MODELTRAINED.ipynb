{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b7f9991-ca89-46ca-b04e-a3d80d6b6b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential    #building rnn\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding ,LSTM  #model layer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2ddb3b-558d-4942-9d7d-bc44107e8692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Area', 'City', 'Restaurant Price', 'Avg Rating', 'Total Rating', 'Food Item', 'Food Type', 'Delivery Time', 'Review']\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('swiggy.csv')\n",
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "898bf095-d943-44c1-b4a7-75e28de44cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID               Area       City  Restaurant Price  Avg Rating  \\\n",
      "0        1             Suburb  Ahmedabad               600         4.2   \n",
      "1        2  Business District       Pune               200         4.7   \n",
      "2        3             Suburb  Bangalore               600         4.7   \n",
      "3        4  Business District     Mumbai               900         4.0   \n",
      "4        5          Tech Park     Mumbai               200         4.7   \n",
      "...    ...                ...        ...               ...         ...   \n",
      "7995  7996        City Center     Mumbai               300         4.0   \n",
      "7996  7997           Downtown    Chennai               100         4.7   \n",
      "7997  7998          Tech Park    Chennai               900         4.5   \n",
      "7998  7999           Old Town      Delhi               500         4.2   \n",
      "7999  8000           Downtown      Delhi               400         4.5   \n",
      "\n",
      "      Total Rating        Food Item       Food Type Delivery Time  \\\n",
      "0             6198            Sushi       Fast Food     30-40 min   \n",
      "1             4865  Pepperoni Pizza  Non-Vegetarian     50-60 min   \n",
      "2             2095          Waffles       Fast Food     50-60 min   \n",
      "3             6639            Sushi      Vegetarian     50-60 min   \n",
      "4             6926     Spring Rolls     Gluten-Free     20-30 min   \n",
      "...            ...              ...             ...           ...   \n",
      "7995          3303         BBQ Ribs           Vegan     20-30 min   \n",
      "7996          8742   Butter Chicken  Non-Vegetarian     20-30 min   \n",
      "7997          4645      Mango Shake       Fast Food     30-40 min   \n",
      "7998          3218   Grilled Cheese  Non-Vegetarian     50-60 min   \n",
      "7999          7739          Burrito           Vegan     30-40 min   \n",
      "\n",
      "                                Review sentiment  \n",
      "0       good but nothing extraordinary  positive  \n",
      "1       good but nothing extraordinary  positive  \n",
      "2              late delivery ruined it  positive  \n",
      "3         best meal ive had in a while  positive  \n",
      "4                  mediocre experience  positive  \n",
      "...                                ...       ...  \n",
      "7995              my new favorite dish  positive  \n",
      "7996  amazing taste and quick delivery  positive  \n",
      "7997        nothing special but edible  positive  \n",
      "7998                       it was okay  positive  \n",
      "7999               delicious and fresh  positive  \n",
      "\n",
      "[8000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "data[\"Review\"]=data[\"Review\"].str.lower()\n",
    "data[\"Review\"] = data[\"Review\"].replace(r'[^a-z0-9\\s]', '', regex=True)\n",
    "def label_sentiment_num(rating):\n",
    "    if rating <= 2.5:\n",
    "        return \"negative\"\n",
    "    elif rating <= 3.5:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "\n",
    "data['sentiment'] = data['Avg Rating'].apply(label_sentiment_num)\n",
    "data=data.dropna()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9704cbf5-4913-4a63-8a74-24ec03446885",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000   \n",
    "max_length = 200    \n",
    "def build_vocab(texts, max_features=None):\n",
    "    word_counts = {}\n",
    "    for text in texts:\n",
    "        for word in text.split():\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "\n",
    "    sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    #limited vocab\n",
    "    if max_features:\n",
    "        sorted_words = sorted_words[:max_features]\n",
    "\n",
    "    word_index = {word: idx+1 for idx, (word, _) in enumerate(sorted_words)}\n",
    "    return word_index\n",
    "\n",
    "word_index = build_vocab(data[\"Review\"].tolist(), max_features=max_features)\n",
    "\n",
    "\n",
    "def texts_to_sequences(texts, word_index):\n",
    "    sequences = []\n",
    "    for text in texts:\n",
    "        seq = [word_index.get(word, 0) for word in text.split()]  \n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "\n",
    "sequences = texts_to_sequences(data[\"Review\"].tolist(), word_index)\n",
    "\n",
    "def pad_sequences_custom(sequences, maxlen):\n",
    "    padded = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) < maxlen:\n",
    "            # pad with zeros at the beginning\n",
    "            seq = [0]*(maxlen - len(seq)) + seq\n",
    "        else:\n",
    "            # truncate \n",
    "            seq = seq[:maxlen]\n",
    "        padded.append(seq)\n",
    "    return np.array(padded)  \n",
    "\n",
    "X = pad_sequences_custom(sequences, max_length)\n",
    "y = data['sentiment'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "435ec05b-f5a5-49eb-89e6-f7ddd7155b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=42, stratify=y_train\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffe9e04f-0bdf-4947-b403-4068b75d79ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "max_words = 5000  # same as tokenizer\n",
    "embedding_dim = 128\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=embedding_dim),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(3, activation=\"softmax\")   # 3 classes\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",  # for integer labels\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4db362f-27d5-4d01-87c3-4e3c0f1fbd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(data[\"sentiment\"])\n",
    "\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_val = encoder.transform(y_val)\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "# Convert to numpy arrays of floats \n",
    "y_train = np.array(y_train).astype(\"float32\")\n",
    "y_val = np.array(y_val).astype(\"float32\")\n",
    "y_test = np.array(y_test).astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "167a1963-fb6c-4bd9-b5c2-28f9a4d5fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_val = y_val.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00341b45-ba5b-4900-9bb0-894be052931c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - accuracy: 0.7160 - loss: 0.5954 - val_accuracy: 0.7156 - val_loss: 0.5957\n",
      "Epoch 2/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 190ms/step - accuracy: 0.7160 - loss: 0.5957 - val_accuracy: 0.7156 - val_loss: 0.5964\n",
      "Epoch 3/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 217ms/step - accuracy: 0.7160 - loss: 0.5958 - val_accuracy: 0.7156 - val_loss: 0.5959\n",
      "Epoch 4/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 228ms/step - accuracy: 0.7160 - loss: 0.5959 - val_accuracy: 0.7156 - val_loss: 0.5961\n",
      "Epoch 5/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 235ms/step - accuracy: 0.7160 - loss: 0.5958 - val_accuracy: 0.7156 - val_loss: 0.5957\n",
      "Epoch 6/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 211ms/step - accuracy: 0.7160 - loss: 0.5962 - val_accuracy: 0.7156 - val_loss: 0.5959\n",
      "Epoch 7/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 214ms/step - accuracy: 0.7160 - loss: 0.5954 - val_accuracy: 0.7156 - val_loss: 0.5961\n",
      "Epoch 8/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 208ms/step - accuracy: 0.7160 - loss: 0.5954 - val_accuracy: 0.7156 - val_loss: 0.5961\n",
      "Epoch 9/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 238ms/step - accuracy: 0.7160 - loss: 0.5952 - val_accuracy: 0.7156 - val_loss: 0.5971\n",
      "Epoch 10/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 253ms/step - accuracy: 0.7160 - loss: 0.5961 - val_accuracy: 0.7156 - val_loss: 0.5964\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.7156 - loss: 0.5978\n",
      "Test Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,        # train longer\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
